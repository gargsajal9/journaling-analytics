# Bash commands used to generate event corpus
# PJ - July 2015

# Extract JSON fields we care about using jq
cat tmp-chrome-all | jq '.data[].data.EvtTime' -c > tmp-chrome-EvtTime.txt
cat tmp-chrome-all | jq '.data[].data.UserId' -c > tmp-chrome-UserId.txt
cat tmp-chrome-all | jq '.data[].data.TaskName' -c > tmp-chrome-TaskName.txt
cat tmp-chrome-all | jq '.data[].data.WebURL' -c > tmp-chrome-WebURL.txt

# Rejoin in a single csv file and sort by time
paste -d, tmp-chrome-EvtTime.txt tmp-chrome-UserId.txt tmp-chrome-TaskName.txt tmp-chrome-WebURL.txt | sed -e 's/\"//g' > tmp-chrome-all-joined.csv
paste -d, tmp-ubuntu-EvtTime.txt tmp-ubuntu-UserId.txt tmp-ubuntu-TaskName.txt tmp-ubuntu-EvtDesc.txt | sed -e 's/\"//g' > tmp-ubuntu-all-joined.csv
cat tmp-chrome-all-joined.csv tmp-ubuntu-all-joined.csv | sort > tmp-all-sorted.csv

# Make TaskName field consistent
cat tmp-all-sorted.csv | sed -e 's/))((/_/g' | sed -e 's/((//' | sed -e 's/))//' | sed -e 's/,/_/g' | sed -e 's/\[//' | sed -e 's/\]//' | sed -e 's/pjones_//' > tmp-all-sorted-cleaned.csv

# Extract only CSC791 records
cat tmp-all-sorted-cleaned.csv | grep CSC791 > tmp-all-sorted-cleaned-csc791.csv
cat tmp-all-sorted-cleaned.csv | grep CSC791 | grep -v None > tmp-all-sorted-cleaned-csc791.csv
cat tmp-all-sorted-cleaned.csv | grep CSC791 | grep -v None | grep -v pj201 > tmp-all-sorted-cleaned-csc791.csv
cat tmp-all-sorted-cleaned-csc791.csv | sed -e 's/\t/,/g' | gzip > csc791-events-all.csv.gz

# Separate by User (and filter for CSC791 and CoyWolf)
cat tmp-all-sorted-cleaned-csc791.csv | grep pjones > csc791-users/pjones.csv

# Do baseline experiments as per Google Doc:
# - Create precision/recall plot for different values of ts_diff between events.
cd csc791-users
python process-full-baseline.py

